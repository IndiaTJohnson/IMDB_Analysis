{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5535eed5-e22a-4877-90e4-fac87fb8849e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'cleaned-basics.csv',\n",
       " 'cleaned-ratings.csv',\n",
       " 'Movies-ERD.png',\n",
       " 'Project2_Part2.sql',\n",
       " 'Project2_Part2_mySQL_Model.mwb',\n",
       " 'title-akas-us-only.csv',\n",
       " 'title.basics.tsv.gz',\n",
       " 'title.ratings.tsv.gz']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import os, time, json\n",
    "import tmdbsimple as tmdb \n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "# Create the folder for saving files (if it doesn't exist)\n",
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485c87ad-4f59-4408-b83b-518464cc6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d759cd6a-7db2-4d31-891f-3ae01e29a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv('Data/cleaned-basics.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacc28c7-380e-4ccb-ac09-360753b0af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2010\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff8bbc0-102e-4f91-994c-037877d8e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821c09f7-7c6e-4c42-93b6-d5608de944d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed446d8-598a-4262-8516-bc33fa7572dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98e5151-5430-4a6a-aaa9-d738309a41f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data/tmdb_api_results_2010.json for API results for 2010.\n"
     ]
    }
   ],
   "source": [
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "    # Print a message indicating the file is being created \n",
    "    print(f\"Creating {JSON_FILE} for API results for {YEAR}.\")\n",
    "    # save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)\n",
    "else: \n",
    "    print(f\"The file {JSON_FILE} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e40e3c5-7c5b-4f0e-b6b4-15debe27b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving new year as the current df\n",
    "df = basics.loc[ basics['startYear'] == YEAR].copy()\n",
    "# saving movie ids to separate variable\n",
    "movie_ids = df['tconst']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87edc44f-0b48-489a-83c5-55efd9484c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "previous_df = pd.read_json(JSON_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f711523-4b53-4736-b391-25a9497f33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b07f138-243f-4660-88de-7b81cee8041c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd747a0a4ba64794bf9d6dad37f0890f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2010:   0%|          | 0/3862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through movie_ids_to_get with a tqdm progress bar\n",
    "for movie_id in tqdm_notebook(movie_ids_to_get, f\"Movies from {YEAR}\"):\n",
    "    #Get index and movie id from list\n",
    "    try:\n",
    "        # Retrieve then data for the movie id\n",
    "        temp = get_movie_with_rating(movie_id)  \n",
    "        # Append/extend results to existing file using a pre-made function\n",
    "        write_json(temp,JSON_FILE)\n",
    "        # Short 20 ms sleep to prevent overwhelming server\n",
    "        time.sleep(0.02)\n",
    "    \n",
    "    except Exception as e:\n",
    "        errors.append([movie_id, e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a32b11-f04e-49c1-89ce-55c9c353036d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 3863\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63a885d5-e768-4e76-8da4-3d05cccbe876",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_year_df = pd.read_json(JSON_FILE)\n",
    "final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fdaba-d90c-4bb2-9d76-49dbe09065be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of previous_df=pd.read_json:\n",
    "#previous_df = read_and_fix_json(JSON_FILE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9c2f6-319e-4321-a826-104c10f954d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e69499-b9e4-4a66-854f-b6ba0193e15e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8e173-ab5c-46ef-b38f-32cbad4f4896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dc6c9-03b0-4f25-85bb-8490a1459099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
